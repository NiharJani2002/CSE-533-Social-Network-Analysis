# -*- coding: utf-8 -*-
"""Rapid_Fire_Presentation_SNA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1evMsxmPQ5R9eSrmV3BuyuFzeT6cqGz_X

# **Primary Requirement:**
1) Downoload the Dataset from NashVille MeetUp Kaggle on Your PC OR DESKTOP

Link: https://www.kaggle.com/datasets/stkbailey/nashville-meetup

The Size is : 11 MB


2) Unzip the file 


3) Upload all the files on Google Collab Using the small folder option on ***Right Hand Side*** of the Google Collab

# ***FREQUENCY PLOT VS WEIGHTS***
"""

import pandas as pd
import matplotlib.pyplot as plt
import networkx as nx

# Load data
graph_edges = pd.read_csv('group-edges.csv')

# Create graph
G = nx.from_pandas_edgelist(graph_edges, source='group1', target='group2', edge_attr='weight')

# Count frequency of weights
weights = [d['weight'] for u,v,d in G.edges(data=True)]
weights_freq = {w:weights.count(w) for w in set(weights)}

# Create plot
fig, ax = plt.subplots()
ax.bar(weights_freq.keys(), weights_freq.values(), width=0.8)

# Set axis labels and title
ax.set_xlabel('Weight')
ax.set_ylabel('Frequency')
ax.set_title('Group-Edges Weight Distribution')

# Set x-axis range and tick frequency
ax.set_xlim([1, 1])
ax.set_xticks(range(1, 17, 1))

# Show plot
plt.show()
#The Highest value is 91
# But since We have limited width on x-axis, we were not able to plot it, but we have created table in decreasing order of freq.

import pandas as pd

# read the graph edges csv file into a pandas dataframe
graph_edges_df = pd.read_csv("group-edges.csv")

# create a new dataframe to store the frequency counts
freq_counts_df = pd.DataFrame({'Frequency': graph_edges_df['weight'].value_counts().sort_index()})

# add a new column with the weight values
freq_counts_df['Weight'] = freq_counts_df.index

# set the index of the dataframe to the weight column
freq_counts_df.set_index('Weight', inplace=True)

# display the dataframe
print(freq_counts_df)

"""# ***Identifying the most popular groups based on the number of members and events attended.***"""

import pandas as pd
import networkx as nx
from tabulate import tabulate

# Load the required dataset
groups_df = pd.read_csv('meta-groups.csv')
member_to_group_edges_df = pd.read_csv('member-to-group-edges.csv')

# Create a bipartite graph of members and groups
G = nx.Graph()
G.add_nodes_from(groups_df['group_id'], bipartite=0)
G.add_nodes_from(member_to_group_edges_df['member_id'], bipartite=1)
G.add_weighted_edges_from(
    member_to_group_edges_df[['member_id', 'group_id', 'weight']].values
)

# Get the number of members in each group
members_per_group = {}
for group_id in groups_df['group_id']:
    members_per_group[group_id] = len(set(nx.neighbors(G, group_id)))

# Get the number of events attended in each group
events_per_group = {}
for group_id in groups_df['group_id']:
    events_per_group[group_id] =events_per_group[group_id] = sum(
    [data['weight'] for (_, _, data) in G.edges(group_id, data=True)]
)

# Get the top 10 most popular groups based on the number of members and events attended
popular_groups = pd.DataFrame({
    'group_id': groups_df['group_id'],
    'name': groups_df['group_name'],
    'category': groups_df['category_name'],
    'members': groups_df['num_members']
}).sort_values(
    by=['members'],
    ascending=[False]
).head(10)

# Print the popular groups table
print(tabulate(popular_groups, headers='keys', tablefmt='fancy_grid'))

import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt

# Load the necessary data
rsvps = pd.read_csv('rsvps.csv')
meta_groups = pd.read_csv('meta-groups.csv')
meta_members = pd.read_csv('meta-members.csv')

# Clean and preprocess the data
rsvps.drop_duplicates(subset=['group_id', 'member_id'], inplace=True)
rsvps['count'] = rsvps['count'].fillna(0)
rsvps = rsvps[rsvps['count'] > 0]

# Create a graph object
G = nx.Graph()

# Add nodes and edges to the graph
for index, row in rsvps.iterrows():
    G.add_node(row['group_id'], bipartite=0)
    G.add_node(row['member_id'], bipartite=1)
    G.add_edge(row['group_id'], row['member_id'], weight=row['count'])

# Analyze the data
print('Number of nodes:', G.number_of_nodes())
print('Number of edges:', G.number_of_edges())

# Identify the key nodes and influencers
degree_dict = dict(G.degree(G.nodes()))
nx.set_node_attributes(G, degree_dict, 'degree')

sorted_degree = sorted(degree_dict.items(), key=lambda x: x[1], reverse=True)

print("Top 10 nodes by degree:")
for d in sorted_degree[:10]:
    print(d)

# Visualize the data
groups = set(n for n, d in G.nodes(data=True) if d['bipartite'] == 0)
members = set(G) - groups

plt.figure(figsize=(10, 10))
pos = dict()
pos.update((n, (1, i)) for i, n in enumerate(groups))
pos.update((n, (2, i)) for i, n in enumerate(members))

nx.draw_networkx_nodes(G, pos, nodelist=groups, node_color='r', node_size=100, alpha=0.8)
nx.draw_networkx_nodes(G, pos, nodelist=members, node_color='g', node_size=100, alpha=0.8)
nx.draw_networkx_edges(G, pos, width=1.0, alpha=0.5)

plt.axis('on')
plt.show()

"""# ***Meta-Group.CSV FILE ANALYSIS***"""

import pandas as pd
import matplotlib.pyplot as plt

# Load the meta-groups.csv file
df_groups = pd.read_csv('meta-groups.csv')

# Group the data by category and organizer_id, and count the number of events hosted
df_events = df_groups.groupby(['category_name', 'organizer_id']).agg({'group_id': 'count'}).reset_index()

# Pivot the data to create a matrix of categories vs organizers, with event counts as values
df_pivot = df_events.pivot(index='category_name', columns='organizer_id', values='group_id')

# Plot a heatmap of the pivot table
plt.figure(figsize=(10, 8))
plt.title('Distribution of events hosted by organizers across different categories')
plt.xlabel('Organizer ID')
plt.ylabel('Category')
plt.imshow(df_pivot, cmap='Blues', aspect='auto')
plt.xticks(range(len(df_pivot.columns)), df_pivot.columns)
plt.yticks(range(len(df_pivot.index)), df_pivot.index)
plt.colorbar()
plt.show()

import pandas as pd
import plotly.graph_objects as go

# Load the necessary data
meta_groups = pd.read_csv("meta-groups.csv")

# Aggregate the number of events hosted by organizers for each category
category_events = meta_groups.groupby("category_name")["num_members"].sum().reset_index()

# Define the labels for the Sankey diagram
categories = category_events["category_name"].tolist()
sources = [0, 1, 2, 3]
targets = [4, 4, 4, 4]

# Define the values for the Sankey diagram
category_values = category_events["num_members"].tolist()
event_values = [sum(category_values)] * 4

# Create the Sankey diagram
fig = go.Figure(data=[go.Sankey(
    node=dict(
        pad=15,
        thickness=20,
        line=dict(color="black", width=0.5),
        label=categories + ["All Events"],
        color=["lightblue", "mediumturquoise", "darkturquoise", "teal", "grey"]
    ),
    link=dict(
        source=sources,
        target=targets,
        value=category_values + event_values,
        color="grey"
    )
)])

fig.update_layout(title="Distribution of Events Hosted by Category",
                  font=dict(size=14),
                  height=500,
                  width=800)

fig.show()